import streamlit as st
from Bio import Entrez
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime, timedelta
import time
import requests
import json
import concurrent.futures # å¼•å…¥å¹³è¡Œè™•ç†åº«

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="GynOnc æ¥µé€Ÿç¿»è­¯ç‰ˆ v8.0", page_icon="âš¡", layout="wide")

# --- Session State ---
if 'articles_data' not in st.session_state: st.session_state.articles_data = []
if 'analysis_cache' not in st.session_state: st.session_state.analysis_cache = {}
if 'email_queue' not in st.session_state: st.session_state.email_queue = []
if 'search_trigger' not in st.session_state: st.session_state.search_trigger = False

# --- å·¥å…·å‡½æ•¸ ---

def clean_input(text):
    """æ¸…ç† API Keyï¼Œå»é™¤ç©ºæ ¼"""
    return text.strip() if text else ""

def clean_json_text(text):
    """æ¸…ç† JSON æ ¼å¼"""
    text = text.strip()
    if text.startswith("```json"): text = text[7:]
    elif text.startswith("```"): text = text[3:]
    if text.endswith("```"): text = text[:-3]
    return text.strip()

# --- æ ¸å¿ƒé‚è¼¯ï¼šå¤šåŸ·è¡Œç·’ç¿»è­¯ ---

def translate_chunk(chunk, key):
    """
    ç¿»è­¯ä¸€å€‹å°å€å¡Š (Worker Function)
    """
    if not chunk: return []
    
    # çµ„åˆ Prompt
    titles_text = "\n".join([f"{i+1}. {art['title']}" for i, art in enumerate(chunk)])
    url = f"[https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=](https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=){key}"
    headers = {'Content-Type': 'application/json'}
    
    prompt = f"""
    Translate these medical titles to Traditional Chinese (Taiwan).
    Format: One translation per line. No numbering. No English.
    
    Titles:
    {titles_text}
    """
    
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        if response.status_code == 200:
            res_text = response.json()['candidates'][0]['content']['parts'][0]['text']
            # åˆ†å‰²å›å‚³çš„æ¯ä¸€è¡Œ
            lines = [l.strip() for l in res_text.strip().split('\n') if l.strip()]
            
            # å°æ‡‰å›æ–‡ç« 
            for i, art in enumerate(chunk):
                if i < len(lines):
                    # ç§»é™¤å¯èƒ½è¢« AI åŠ ä¸Šçš„ç·¨è™Ÿ
                    clean_zh = lines[i].split(". ", 1)[-1] if ". " in lines[i][:4] else lines[i]
                    art['title_zh'] = clean_zh
                else:
                    art['title_zh'] = art['title'] # æ²’ç¿»åˆ°å°±é¡¯ç¤ºåŸæ–‡
        else:
            for art in chunk: art['title_zh'] = "(ç¿»è­¯å¿™ç¢Œä¸­)"
    except:
        for art in chunk: art['title_zh'] = "(é€£ç·šéŒ¯èª¤)"
        
    return chunk

def batch_translate_parallel(articles, key):
    """
    ä¸»æ§å°ï¼šå°‡æ–‡ç« åˆ†çµ„ï¼Œä¸¦ç™¼é€çµ¦å¤šå€‹ Worker åŒæ™‚è·‘
    """
    chunk_size = 10 # æ¯ä¸€çµ„ 10 ç¯‡
    chunks = [articles[i:i + chunk_size] for i in range(0, len(articles), chunk_size)]
    
    results = []
    
    # é–‹å•Ÿ 3 å€‹åŸ·è¡Œç·’ (Thread) åŒæ™‚è·‘
    # æ³¨æ„ï¼šå…è²»ç‰ˆ API é™åˆ¶è¼ƒå¤šï¼Œé–‹å¤ªå¤šæœƒè¢«æ“‹ï¼Œ3 å€‹æ˜¯å®‰å…¨å€¼
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        # æäº¤ä»»å‹™
        future_to_chunk = {executor.submit(translate_chunk, chunk, key): chunk for chunk in chunks}
        
        # ç­‰å¾…çµæœ
        for future in concurrent.futures.as_completed(future_to_chunk):
            try:
                data = future.result()
                results.extend(data)
            except Exception as e:
                pass
                
    # å› ç‚ºå¤šåŸ·è¡Œç·’å›å‚³é †åºä¸å›ºå®šï¼Œé€™è£¡ç°¡å–®è™•ç†ç›´æ¥å›å‚³çµæœåˆ—è¡¨
    # (å¦‚æœå¾ˆåœ¨æ„é †åºï¼Œå¯ä»¥ç”¨ mapï¼Œä½† list extend å¤ ç”¨äº†)
    return sorted(results, key=lambda x: articles.index(x)) # å˜—è©¦æ¢å¾©åŸæœ¬é †åº (ä¾è³´ object id æˆ–å…§å®¹)

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("âš¡ æ¥µé€Ÿç¿»è­¯è¨­å®š")
    
    # 1. è³¼ç‰©è»Š
    if st.session_state.email_queue:
        with st.expander(f"ğŸ›’ è³¼ç‰©è»Š ({len(st.session_state.email_queue)})", expanded=True):
            if 'EMAIL_ADDRESS' in st.secrets: user_email = st.secrets['EMAIL_ADDRESS']
            else: user_email = st.text_input("Email", "lionsmanic@gmail.com")
            
            if 'EMAIL_PASSWORD' in st.secrets: email_password = st.secrets['EMAIL_PASSWORD']
            else: email_password = st.text_input("Gmail App Password", type="password")

            if st.button("ğŸ“© å¯„å‡º", type="primary"):
                st.session_state.trigger_email = True
    
    st.divider()

    # 2. API Key (Auto Clean)
    if 'GEMINI_API_KEY' in st.secrets:
        api_key = st.secrets['GEMINI_API_KEY']
        st.success("ğŸ”‘ Key Ready")
    else:
        raw_key = st.text_input("Gemini API Key", type="password")
        api_key = clean_input(raw_key)

    st.divider()
    
    # 3. æœå°‹
    st.subheader("ğŸ” æ¢ä»¶")
    KEYWORDS = {
        "ğŸ¥š å©¦ç™Œ": ["cervical cancer", "ovarian cancer", "endometrial cancer", "immunotherapy", "robotic surgery"],
        "ğŸŒŠ æµ·æ‰¶åˆ€": ["HIFU", "high intensity focused ultrasound", "uterine leiomyoma", "adenomyosis"],
        "ğŸ§¬ ç²¾æº–": ["genetic test", "targeted therapy"]
    }
    
    sel_cat = st.multiselect("é¡åˆ¥", list(KEYWORDS.keys()), ["ğŸ¥š å©¦ç™Œ"])
    base_k = []
    for c in sel_cat: base_k.extend(KEYWORDS[c])
    cust_k = st.text_input("è‡ªè¨‚", help="e.g. TP53")
    if cust_k: base_k.extend([k.strip() for k in cust_k.split(",")])
    final_k = st.multiselect("é—œéµå­—", base_k, base_k)

    use_j = st.checkbox("é™å®šæœŸåˆŠ", True)
    PRESET_J = ["New England Journal of Medicine", "The Lancet Oncology", "Journal of Clinical Oncology", "Gynecologic Oncology", "Journal of Gynecologic Oncology"]
    final_j = st.multiselect("æœŸåˆŠ", PRESET_J, PRESET_J) if use_j else []

    days_back = st.slider("å¹¾å¤©å…§?", 1, 90, 14)
    max_res = st.number_input("ç¯‡æ•¸", 1, 50, 10) # å»ºè­° 20 ç¯‡å…§é«”é©—æœ€å¥½
    
    if st.button("ğŸš€ æœå°‹ä¸¦ç¿»è­¯", type="primary"):
        if not api_key: st.error("ç¼º API Key")
        else:
            st.session_state.articles_data = []
            st.session_state.search_trigger = True

# --- ä¸»ç¨‹å¼å‡½æ•¸ ---

def build_query(keywords, journals, days):
    q = "(" + " OR ".join([f'"{k}"[Title/Abstract]' for k in keywords]) + ")"
    if journals: q = f"{q} AND (" + " OR ".join([f'"{j}"[Journal]' for j in journals]) + ")"
    return q

def fetch_headers(query, days, limit, email):
    Entrez.email = email
    try:
        h = Entrez.esearch(db="pubmed", term=query, reldate=days, retmax=limit, sort="date")
        r = Entrez.read(h)
        ids = r["IdList"]
        if not ids: return []
        
        h = Entrez.efetch(db="pubmed", id=ids, retmode="xml")
        arts = Entrez.read(h)
        parsed = []
        for art in arts['PubmedArticle']:
            try:
                cit = art['MedlineCitation']
                ti = cit['Article']['ArticleTitle']
                jo = cit['Article']['Journal']['Title']
                ab = " ".join([str(x) for x in cit['Article']['Abstract']['AbstractText']]) if 'Abstract' in cit['Article'] else "No Abstract"
                ids = art['PubmedData']['ArticleIdList']
                doi = next((i for i in ids if i.attributes['IdType']=='doi'), None)
                link = f"[https://doi.org/](https://doi.org/){doi}" if doi else f"[https://pubmed.ncbi.nlm.nih.gov/](https://pubmed.ncbi.nlm.nih.gov/){ids[0]}/"
                parsed.append({"id": ids[0], "title":ti, "journal":jo, "abstract":ab, "link":link, "title_zh": "ç¿»è­¯ä¸­..."})
            except: continue
        return parsed
    except: return []

def run_deep_analysis_json(art, key):
    url = f"[https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=](https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=){key}"
    headers = {'Content-Type': 'application/json'}
    
    prompt = f"""
    Analyze abstract. Return JSON only. Keys: methods, rationale, results, implication. Values in Traditional Chinese.
    Title: {art['title']}
    Abstract: {art['abstract']}
    """
    
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    try:
        res = requests.post(url, headers=headers, data=json.dumps(payload))
        if res.status_code == 200:
            txt = clean_json_text(res.json()['candidates'][0]['content']['parts'][0]['text'])
            data = json.loads(txt)
            return f"""
            <div style="background:#fff; padding:15px; border-radius:8px; border:1px solid #eee;">
                <h4 style="color:#2e86c1;">1. ğŸ§ª ç ”ç©¶æ–¹æ³•</h4><div>{data.get('methods','')}</div>
                <h4 style="color:#2e86c1;">2. ğŸ’¡ ç™¼æƒ³ç·£èµ·</h4><div>{data.get('rationale','')}</div>
                <h4 style="color:#2e86c1;">3. ğŸ“Š çµæœæ•¸æ“š</h4><div>{data.get('results','')}</div>
                <h4 style="color:#d35400;">4. ğŸ¥ è‡¨åºŠé‹ç”¨</h4><div>{data.get('implication','')}</div>
            </div>
            """
    except: return "<div style='color:red'>åˆ†æå¤±æ•—</div>"
    return "<div style='color:red'>é€£ç·šå¤±æ•—</div>"

def send_mail(to, pwd, queue):
    msg = MIMEMultipart()
    msg['From'] = to
    msg['To'] = to
    msg['Subject'] = f"GynOnc Report {datetime.now().strftime('%Y-%m-%d')}"
    body = "<html><body><h2>æ–‡ç»å ±å‘Š</h2><hr>" + "".join([i['html'] + "<hr>" for i in queue]) + "</body></html>"
    msg.attach(MIMEText(body, 'html'))
    try:
        s = smtplib.SMTP('smtp.gmail.com', 587); s.starttls()
        s.login(to, pwd); s.send_message(msg); s.quit()
        return True, "OK"
    except Exception as e: return False, str(e)

# --- ä¸»æµç¨‹ ---

st.title("âš¡ GynOnc æ¥µé€Ÿç¿»è­¯ç‰ˆ v8.0")

if st.session_state.search_trigger:
    # ç‚ºäº†é¿å…è®Šæ•¸éŒ¯èª¤ï¼Œé€™è£¡å®šç¾©è‡¨æ™‚ email
    temp_email = "lionsmanic@gmail.com"
    if 'EMAIL_ADDRESS' in st.secrets: temp_email = st.secrets['EMAIL_ADDRESS']
    
    with st.status("ğŸš€ å•Ÿå‹•å¤šæ ¸å¿ƒå¼•æ“ï¼šæœå°‹ + å¹³è¡Œç¿»è­¯ä¸­...", expanded=True) as status:
        q = build_query(final_k, final_j, days_back)
        raw = fetch_headers(q, {"reldate": days_back}, max_res, temp_email)
        
        if raw:
            st.write(f"âœ… æ‰¾åˆ° {len(raw)} ç¯‡ï¼Œæ­£åœ¨åŒæ™‚ç¿»è­¯...")
            # é—œéµï¼šå¹³è¡Œç¿»è­¯
            final_list = batch_translate_parallel(raw, api_key)
            st.session_state.articles_data = final_list
            status.update(label="å®Œæˆï¼", state="complete")
        else:
            status.update(label="ç„¡çµæœ", state="error")
    st.session_state.search_trigger = False

# é¡¯ç¤ºåˆ—è¡¨
if st.session_state.articles_data:
    st.divider()
    for i, art in enumerate(st.session_state.articles_data):
        with st.container():
            c1, c2 = st.columns([5, 1])
            with c1:
                # é€™è£¡ç›´æ¥é¡¯ç¤ºç¿»è­¯å¥½çš„æ¨™é¡Œ
                st.markdown(f"**{i+1}. {art['title']}**")
                # è—è‰²å¤§å­—é«”é¡¯ç¤ºä¸­æ–‡æ¨™é¡Œ
                st.markdown(f"<h4 style='color:#1a5276; margin-top:0;'>{art.get('title_zh', '...')}</h4>", unsafe_allow_html=True)
                st.caption(f"ğŸ“– {art['journal']} | [Link]({art['link']})")
            
            with c2:
                if st.button("ğŸ” è©³ç´°åˆ†æ", key=f"btn_{i}"):
                    with st.spinner("åˆ†æä¸­..."):
                        if art['id'] not in st.session_state.analysis_cache:
                            report = run_deep_analysis_json(art, api_key)
                            st.session_state.analysis_cache[art['id']] = report
                            
                            # åŠ å…¥è³¼ç‰©è»Š
                            st.session_state.email_queue.append({
                                "title": art['title'],
                                "html": f"<h3>{art['title']}</h3><h4>{art['title_zh']}</h4>{report}"
                            })
                            st.rerun()

            if art['id'] in st.session_state.analysis_cache:
                with st.expander("ğŸ©º æ·±åº¦å ±å‘Š", expanded=True):
                    st.markdown(st.session_state.analysis_cache[art['id']], unsafe_allow_html=True)
            st.markdown("---")

if getattr(st.session_state, 'trigger_email', False):
    # å†æ¬¡ç²å–å¯†ç¢¼ (éœ€è¦ç¢ºä¿ sidebar è®Šæ•¸å¯åŠæ€§ï¼Œæˆ–ä½¿ç”¨ secrets)
    m_to = "lionsmanic@gmail.com"
    m_pwd = ""
    if 'EMAIL_ADDRESS' in st.secrets: m_to = st.secrets['EMAIL_ADDRESS']
    if 'EMAIL_PASSWORD' in st.secrets: m_pwd = st.secrets['EMAIL_PASSWORD']
    
    # å¦‚æœæ²’è¨­å®š secretsï¼Œé€™è£¡æœƒå¤±æ•—ï¼Œå»ºè­°æ­£å¼ç’°å¢ƒå‹™å¿…è¨­ secrets
    ok, msg = send_mail(m_to, m_pwd, st.session_state.email_queue)
    if ok: 
        st.sidebar.success("å·²å¯„å‡º")
        st.session_state.email_queue = []
    else: st.sidebar.error(f"å¤±æ•—: {msg}")
    st.session_state.trigger_email = False
