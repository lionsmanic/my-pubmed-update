import streamlit as st
from Bio import Entrez
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime, timedelta
import time
import requests
import json

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="GynOnc æ–‡ç»å¿«ç¯©ç³»çµ± v4.0", page_icon="âš¡", layout="wide")

# --- Session State åˆå§‹åŒ– (é—œéµï¼šç”¨æ–¼è¨˜ä½æœå°‹çµæœèˆ‡åˆ†æç·©å­˜) ---
if 'articles_data' not in st.session_state:
    st.session_state.articles_data = []  # å­˜æœå°‹åˆ°çš„æ‰€æœ‰æ–‡ç« ç°¡ä»‹
if 'analysis_cache' not in st.session_state:
    st.session_state.analysis_cache = {} # å­˜å·²ç¶“åˆ†æéçš„è©³ç´°å…§å®¹ {doi: html}
if 'email_queue' not in st.session_state:
    st.session_state.email_queue = []    # æº–å‚™å¯„å‡ºçš„æ¸…å–®

# --- æ ¸å¿ƒå‡½æ•¸ï¼šæ¨¡å‹åµæ¸¬ ---
def get_available_models(api_key):
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
    try:
        response = requests.get(url)
        if response.status_code == 200:
            data = response.json()
            models = [m['name'].replace('models/', '') for m in data.get('models', []) 
                      if 'generateContent' in m.get('supportedGenerationMethods', [])]
            return models
        return []
    except: return []

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("âš¡ è¨­å®šèˆ‡å¿«ç¯©")
    
    # 1. API Key
    if 'GEMINI_API_KEY' in st.secrets:
        api_key = st.secrets['GEMINI_API_KEY']
        st.success("ğŸ”‘ API Key å·²è¼‰å…¥")
    else:
        api_key = st.text_input("Gemini API Key", type="password")

    # æ¨¡å‹é¸æ“‡
    selected_model_name = None
    if api_key:
        available_models = get_available_models(api_key)
        if available_models:
            default_ix = 0
            if 'gemini-1.5-flash' in available_models: default_ix = available_models.index('gemini-1.5-flash')
            elif 'gemini-pro' in available_models: default_ix = available_models.index('gemini-pro')
            selected_model_name = st.selectbox("âœ… AI æ¨¡å‹:", available_models, index=default_ix)

    # 2. Email
    if 'EMAIL_ADDRESS' in st.secrets:
        user_email = st.secrets['EMAIL_ADDRESS']
    else:
        user_email = st.text_input("Email", "lionsmanic@gmail.com")
    
    if 'EMAIL_PASSWORD' in st.secrets:
        email_password = st.secrets['EMAIL_PASSWORD']
    else:
        email_password = st.text_input("Gmail App Password", type="password")

    st.divider()
    
    # 3. æœå°‹è¨­å®š
    st.subheader("ğŸ” æœå°‹æ¢ä»¶")
    
    KEYWORDS = {
        "ğŸ¥š å©¦ç™Œ (Gyn Onc)": ["cervical cancer", "ovarian cancer", "endometrial cancer", "immunotherapy", "robotic surgery"],
        "ğŸŒŠ æµ·æ‰¶åˆ€ (HIFU)": ["HIFU", "high intensity focused ultrasound", "uterine leiomyoma", "adenomyosis"],
        "ğŸ§¬ ç²¾æº–/å…¶ä»–": ["genetic test", "targeted therapy"]
    }
    
    selected_cats = st.multiselect("ğŸ“š ä¸»é¡Œé¡åˆ¥", list(KEYWORDS.keys()), default=["ğŸ¥š å©¦ç™Œ (Gyn Onc)"])
    base_keywords = []
    for cat in selected_cats:
        base_keywords.extend(KEYWORDS[cat])
    
    custom_keywords_str = st.text_input("â• è‡ªè¨‚é—œéµå­—", help="ä¾‹å¦‚: TP53, toxicity")
    if custom_keywords_str:
        base_keywords.extend([k.strip() for k in custom_keywords_str.split(",") if k.strip()])
    
    final_keywords = st.multiselect("æœ€çµ‚é—œéµå­—", base_keywords, default=base_keywords)

    use_journals = st.checkbox("é™å®šæ¬Šå¨æœŸåˆŠ?", value=True)
    PRESET_JOURNALS = ["New England Journal of Medicine", "The Lancet Oncology", "Journal of Clinical Oncology", "Gynecologic Oncology"]
    final_journals = st.multiselect("é¸æ“‡æœŸåˆŠ", PRESET_JOURNALS, default=PRESET_JOURNALS) if use_journals else []

    st.divider()

    # 4. æ™‚é–“èˆ‡æ•¸é‡
    date_mode = st.radio("ğŸ“… æ™‚é–“æ¨¡å¼", ["æœ€è¿‘å¹¾å¤©", "æŒ‡å®šå€é–“"], index=0)
    date_range_query = ""
    date_params = {}
    
    if date_mode == "æœ€è¿‘å¹¾å¤©":
        days_back = st.slider("éå»å¹¾å¤©?", 1, 90, 14)
        date_params = {"reldate": days_back}
    else:
        col1, col2 = st.columns(2)
        with col1: day_start = st.number_input("å¹¾å¤©å‰é–‹å§‹?", 1, 365, 60)
        with col2: day_end = st.number_input("å¹¾å¤©å‰çµæŸ?", 0, 365, 30)
        today = datetime.now()
        d_min = (today - timedelta(days=day_start)).strftime("%Y/%m/%d")
        d_max = (today - timedelta(days=day_end)).strftime("%Y/%m/%d")
        date_range_query = f' AND ("{d_min}"[Date - Publication] : "{d_max}"[Date - Publication])'

    # æ•¸é‡è¨­å®š (0-100)
    max_results = st.number_input("åˆ—å‡ºç¯‡æ•¸ä¸Šé™ (Max Results)", min_value=1, max_value=100, value=20)
    
    # æœå°‹æŒ‰éˆ•
    if st.button("ğŸš€ æ¥µé€Ÿæœå°‹ (åˆ—å‡ºæ¨™é¡Œ)", type="primary", disabled=(not selected_model_name)):
        # æ¸…ç©ºèˆŠè³‡æ–™
        st.session_state.articles_data = []
        st.session_state.analysis_cache = {}
        st.session_state.email_queue = []
        st.session_state.search_trigger = True # è§¸ç™¼æœå°‹æ¨™è¨˜

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸ ---

def build_query(keywords, journals, date_str_query):
    if not keywords: return ""
    term_q = "(" + " OR ".join([f'"{k}"[Title/Abstract]' for k in keywords]) + ")"
    final = term_q
    if journals:
        journal_q = "(" + " OR ".join([f'"{j}"[Journal]' for j in journals]) + ")"
        final = f"{term_q} AND {journal_q}"
    if date_str_query: final += date_str_query
    return final

def fetch_headers(query, date_params, limit, email):
    Entrez.email = email
    try:
        search_args = {"db": "pubmed", "term": query, "retmax": limit, "sort": "date"}
        if "reldate" in date_params: search_args["reldate"] = date_params["reldate"]
        
        h = Entrez.esearch(**search_args)
        r = Entrez.read(h)
        ids = r["IdList"]
        if not ids: return []
        
        # æŠ“å–æ‘˜è¦è³‡è¨Š
        h = Entrez.efetch(db="pubmed", id=ids, retmode="xml")
        arts = Entrez.read(h)
        parsed = []
        for art in arts['PubmedArticle']:
            try:
                cit = art['MedlineCitation']
                ti = cit['Article']['ArticleTitle']
                jo = cit['Article']['Journal']['Title']
                ab = " ".join([str(x) for x in cit['Article']['Abstract']['AbstractText']]) if 'Abstract' in cit['Article'] else "No Abstract"
                ids = art['PubmedData']['ArticleIdList']
                doi = next((i for i in ids if i.attributes['IdType']=='doi'), None)
                link = f"https://doi.org/{doi}" if doi else f"https://pubmed.ncbi.nlm.nih.gov/{ids[0]}/"
                parsed.append({"id": ids[0], "title":ti, "journal":jo, "abstract":ab, "link":link, "title_zh": "ç¿»è­¯ä¸­..."})
            except: continue
        return parsed
    except Exception as e:
        st.error(f"PubMed Error: {e}"); return []

def batch_translate_titles(articles, key, model_name):
    """
    ä¸€æ¬¡å°‡æ‰€æœ‰æ¨™é¡Œæ‰“åŒ…é€çµ¦ AI ç¿»è­¯ (æ‰¹æ¬¡è™•ç†ï¼Œé€Ÿåº¦æ¥µå¿«)
    """
    if not articles: return []
    
    # æº–å‚™ Promptï¼Œå°‡æ¨™é¡Œåˆ—è¡¨åŒ–
    titles_text = "\n".join([f"{i+1}. {art['title']}" for i, art in enumerate(articles)])
    
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={key}"
    headers = {'Content-Type': 'application/json'}
    
    prompt = f"""
    ä»»å‹™ï¼šå°‡ä»¥ä¸‹ {len(articles)} å€‹é†«å­¸è«–æ–‡æ¨™é¡Œç¿»è­¯æˆã€Œå°ç£ç¹é«”ä¸­æ–‡ã€ã€‚
    æ ¼å¼ï¼šè«‹åš´æ ¼æŒ‰ç…§é †åºï¼Œä¸€è¡Œä¸€å€‹ç¿»è­¯çµæœï¼Œä¸è¦æœ‰ç·¨è™Ÿï¼Œä¸è¦æœ‰é¡å¤–æ–‡å­—ã€‚
    
    åŸæ–‡æ¨™é¡Œï¼š
    {titles_text}
    """
    
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        if response.status_code == 200:
            res_text = response.json()['candidates'][0]['content']['parts'][0]['text']
            # åˆ†å‰²å›å‚³çš„è¡Œ
            zh_titles = [line.strip() for line in res_text.strip().split('\n') if line.strip()]
            
            # ç¢ºä¿é•·åº¦ä¸€è‡´ (AIæœ‰æ™‚å€™æœƒå°‘ç¿»æˆ–å¤šç·¨è™Ÿ)
            for i, art in enumerate(articles):
                if i < len(zh_titles):
                    # ç§»é™¤å¯èƒ½å­˜åœ¨çš„ç·¨è™Ÿ (å¦‚ "1. ")
                    clean_title = zh_titles[i].split(". ", 1)[-1] if ". " in zh_titles[i][:4] else zh_titles[i]
                    art['title_zh'] = clean_title
                else:
                    art['title_zh'] = "(ç¿»è­¯å¤±æ•—)"
    except:
        pass # å¤±æ•—å°±ç¶­æŒåŸæ¨£
    return articles

def run_deep_analysis(art, key, model_name):
    """å–®ç¯‡æ·±åº¦åˆ†æ"""
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={key}"
    headers = {'Content-Type': 'application/json'}
    
    prompt_text = f"""
    è§’è‰²ï¼šè³‡æ·±å©¦ç™Œæ¬Šå¨é†«å¸«ã€‚
    ä»»å‹™ï¼šé‡å°ä»¥ä¸‹é€™ç¯‡è«–æ–‡é€²è¡Œè©³ç´°çš„å­¸è¡“é»è©•ã€‚
    
    æ¨™é¡Œï¼š{art['title']}
    æ‘˜è¦ï¼š{art['abstract']}
    
    è«‹ä»¥ HTML æ ¼å¼ (ä¸å« markdown) è¼¸å‡ºä»¥ä¸‹çµæ§‹åˆ†æï¼š
    <div style="background:#fff; padding:15px; border:1px solid #ddd; border-radius:5px;">
        <h4 style="color:#2e86c1; margin-top:0;">1. ğŸ§ª ç ”ç©¶æ–¹æ³• (Methods)</h4>
        <p>è«‹ç°¡è¿° Study Design, Patient Population, Interventionã€‚</p>
        
        <h4 style="color:#2e86c1;">2. ğŸ’¡ ç™¼æƒ³ç·£èµ· (Rationale)</h4>
        <p>æ¨æ¸¬ä½œè€…ç‚ºä½•é€²è¡Œæ­¤ç ”ç©¶ï¼Ÿè§£æ±ºäº†ä»€éº¼è‡¨åºŠç—›é»ï¼Ÿ</p>
        
        <h4 style="color:#2e86c1;">3. ğŸ“Š çµæœæ•¸æ“š (Results)</h4>
        <p>è«‹åˆ—å‡ºé—œéµ P-value, HR, OR, Response Rate ç­‰å…·é«”æ•¸æ“šã€‚</p>
        
        <h4 style="color:#d35400;">4. ğŸ¥ è‡¨åºŠé‹ç”¨èˆ‡çµè«– (Clinical Implication)</h4>
        <p>é€™å°å©¦ç™Œè‡¨åºŠå¯¦è¸æœ‰ä½•å…·é«”æ”¹è®Šæˆ–å»ºè­°ï¼Ÿ</p>
    </div>
    """
    
    payload = {"contents": [{"parts": [{"text": prompt_text}]}]}
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload))
        if response.status_code == 200:
            txt = response.json()['candidates'][0]['content']['parts'][0]['text']
            return txt.replace("```html", "").replace("```", "")
        else: return f"<div style='color:red'>åˆ†æå¤±æ•—: {response.text}</div>"
    except Exception as e: return f"<div style='color:red'>éŒ¯èª¤: {str(e)}</div>"

def send_bulk_email(to, pwd, queue):
    if not queue: return False, "æ¸…å–®ç‚ºç©º"
    msg = MIMEMultipart()
    msg['From'] = to
    msg['To'] = to
    msg['Subject'] = f"GynOnc ç²¾é¸æ–‡ç»å½™å ± ({len(queue)}ç¯‡) - {datetime.now().strftime('%Y-%m-%d')}"
    
    body = "<h2>ğŸ§¬ æ‚¨çš„ç²¾é¸æ–‡ç»åˆ†æå ±å‘Š</h2><hr>"
    for item in queue:
        body += item['html']
        body += "<hr>"
    
    msg.attach(MIMEText(body, 'html'))
    try:
        s = smtplib.SMTP('smtp.gmail.com', 587)
        s.starttls()
        s.login(to, pwd)
        s.send_message(msg); s.quit()
        return True, "å·²å¯„å‡º"
    except Exception as e: return False, str(e)

# --- ä¸»ç¨‹å¼é‚è¼¯ ---

st.title("âš¡ GynOnc æ–‡ç»å¿«ç¯©ç³»çµ±")
st.caption("å…ˆåˆ—æ¸…å–®ï¼Œå†é»é¸æ·±å…¥åˆ†æ")

# 1. åŸ·è¡Œæœå°‹ (åªæŠ“æ¨™é¡Œå’Œæ‘˜è¦ï¼Œä¸åšåˆ†æ)
if getattr(st.session_state, 'search_trigger', False):
    with st.status("ğŸ” æ­£åœ¨æœå°‹ PubMed ä¸¦æ‰¹æ¬¡ç¿»è­¯æ¨™é¡Œ...", expanded=True) as status:
        q = build_query(final_keywords, final_journals, date_range_query)
        st.write(f"æœå°‹èªæ³•: `{q[:50]}...`")
        
        # æŠ“å–è³‡æ–™
        raw_articles = fetch_headers(q, date_params, max_results, user_email)
        
        if raw_articles:
            st.write(f"âœ… æ‰¾åˆ° {len(raw_articles)} ç¯‡ï¼Œæ­£åœ¨é€²è¡Œ AI æ¨™é¡Œæ‰¹æ¬¡ç¿»è­¯...")
            # æ‰¹æ¬¡ç¿»è­¯æ¨™é¡Œ (é€™ä¸€æ­¥å¾ˆå¿«)
            translated_articles = batch_translate_titles(raw_articles, api_key, selected_model_name)
            st.session_state.articles_data = translated_articles
            status.update(label="æœå°‹å®Œæˆï¼è«‹åœ¨ä¸‹æ–¹åˆ—è¡¨é»é¸æŸ¥çœ‹ã€‚", state="complete")
        else:
            status.update(label="âŒ æ‰¾ä¸åˆ°æ–‡ç« ", state="error")
    
    st.session_state.search_trigger = False # é—œé–‰è§¸ç™¼å™¨

# 2. é¡¯ç¤ºåˆ—è¡¨ (å¿«ç¯©ä»‹é¢)
if st.session_state.articles_data:
    st.divider()
    st.markdown(f"### ğŸ“š æœå°‹çµæœåˆ—è¡¨ ({len(st.session_state.articles_data)} ç¯‡)")
    
    for i, art in enumerate(st.session_state.articles_data):
        # ä½¿ç”¨å®¹å™¨æ¡†ä½æ¯ä¸€ç¯‡
        with st.container():
            col1, col2 = st.columns([5, 1])
            
            with col1:
                # é¡¯ç¤ºæ¨™é¡Œèˆ‡ä¸­æ–‡æ¨™é¡Œ
                st.markdown(f"**{i+1}. {art['title']}**")
                st.markdown(f"<span style='color:#2e86c1; font-size:1.1em;'>{art['title_zh']}</span>", unsafe_allow_html=True)
                st.caption(f"ğŸ“– {art['journal']} | ğŸ—“ï¸ [åŸæ–‡é€£çµ]({art['link']})")
            
            with col2:
                # åˆ†ææŒ‰éˆ• (Unique key very important)
                btn_key = f"analyze_btn_{i}"
                if st.button("ğŸ” è©³ç´°åˆ†æ", key=btn_key):
                    # é»æ“Šæ™‚ï¼Œé¦¬ä¸ŠåŸ·è¡Œåˆ†æä¸¦å­˜å…¥ Cache
                    with st.spinner("AI æ­£åœ¨æ·±åº¦é–±è®€æ­¤ç¯‡æ–‡ç« ..."):
                        if art['id'] not in st.session_state.analysis_cache:
                            report = run_deep_analysis(art, api_key, selected_model_name)
                            st.session_state.analysis_cache[art['id']] = report
                            
                            # è‡ªå‹•åŠ å…¥ Email ä½‡åˆ—
                            email_item = {
                                "title": art['title'],
                                "html": f"<h3><a href='{art['link']}'>{art['title']} ({art['title_zh']})</a></h3><p>{art['journal']}</p>{report}"
                            }
                            # é¿å…é‡è¤‡åŠ å…¥
                            if not any(d['title'] == art['title'] for d in st.session_state.email_queue):
                                st.session_state.email_queue.append(email_item)

            # å¦‚æœ Cache è£¡æœ‰é€™ç¯‡çš„å ±å‘Šï¼Œå°±å±•é–‹é¡¯ç¤º
            if art['id'] in st.session_state.analysis_cache:
                with st.expander("ğŸ©º æŸ¥çœ‹ AI æ·±åº¦åˆ†æå ±å‘Š", expanded=True):
                    st.markdown(st.session_state.analysis_cache[art['id']], unsafe_allow_html=True)
            
            st.markdown("---")

# 3. è³¼ç‰©è»Š/å¯„ä¿¡å€
if st.session_state.email_queue:
    st.sidebar.divider()
    st.sidebar.header(f"ğŸ›’ å·²é¸æ–‡ç» ({len(st.session_state.email_queue)})")
    st.sidebar.info("æ‚¨é»æ“Šéã€Œè©³ç´°åˆ†æã€çš„æ–‡ç« éƒ½æœƒè‡ªå‹•åŠ å…¥æ­¤æ¸…å–®ã€‚")
    
    if st.sidebar.button("ğŸ“© æ‰“åŒ…å¯„å‡ºæ‰€æœ‰å·²åˆ†ææ–‡ç»", type="primary"):
        if not email_password:
            st.sidebar.error("è«‹è¼¸å…¥ Gmail App Password")
        else:
            ok, msg = send_bulk_email(user_email, email_password, st.session_state.email_queue)
            if ok:
                st.sidebar.success("âœ… éƒµä»¶å·²å¯„å‡ºï¼")
                st.session_state.email_queue = [] # æ¸…ç©º
            else:
                st.sidebar.error(f"âŒ å¤±æ•—: {msg}")
