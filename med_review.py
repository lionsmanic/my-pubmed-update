import streamlit as st
from Bio import Entrez
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime, timedelta
import time
import requests
import json
import concurrent.futures

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="GynOnc æ¥µé€Ÿæ–‡ç»ç³»çµ± v9.0", page_icon="âš¡", layout="wide")

# --- Session State ---
if 'articles_data' not in st.session_state: st.session_state.articles_data = []
if 'analysis_cache' not in st.session_state: st.session_state.analysis_cache = {}
if 'email_queue' not in st.session_state: st.session_state.email_queue = []
if 'search_trigger' not in st.session_state: st.session_state.search_trigger = False

# --- å·¥å…·å‡½æ•¸ ---
def clean_input(text):
    return text.strip() if text else ""

def clean_json_text(text):
    text = text.strip()
    if text.startswith("```json"): text = text[7:]
    elif text.startswith("```"): text = text[3:]
    if text.endswith("```"): text = text[:-3]
    return text.strip()

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("âš¡ è¨­å®šèˆ‡è³¼ç‰©è»Š")
    
    # 1. è³¼ç‰©è»Š (ç½®é ‚)
    if st.session_state.email_queue:
        with st.expander(f"ğŸ›’ è³¼ç‰©è»Š ({len(st.session_state.email_queue)})", expanded=True):
            for item in st.session_state.email_queue:
                st.text(f"â€¢ {item['title'][:20]}...")
                
            if 'EMAIL_ADDRESS' in st.secrets: user_email = st.secrets['EMAIL_ADDRESS']
            else: user_email = st.text_input("Email", "lionsmanic@gmail.com")
            
            if 'EMAIL_PASSWORD' in st.secrets: email_password = st.secrets['EMAIL_PASSWORD']
            else: email_password = st.text_input("Gmail App Password", type="password")

            if st.button("ğŸ“© å¯„å‡º", type="primary"):
                st.session_state.trigger_email = True
    else:
        st.info("è³¼ç‰©è»Šæ˜¯ç©ºçš„")
    
    st.divider()

    # 2. API Key
    if 'GEMINI_API_KEY' in st.secrets:
        api_key = st.secrets['GEMINI_API_KEY']
        st.success("ğŸ”‘ Key Ready")
    else:
        raw_key = st.text_input("Gemini API Key", type="password")
        api_key = clean_input(raw_key)

    st.divider()
    
    # 3. æœå°‹æ¢ä»¶
    st.subheader("ğŸ” æœå°‹æ¢ä»¶")
    KEYWORDS = {
        "ğŸ¥š å©¦ç™Œ": ["cervical cancer", "ovarian cancer", "endometrial cancer", "immunotherapy", "robotic surgery"],
        "ğŸŒŠ æµ·æ‰¶åˆ€": ["HIFU", "high intensity focused ultrasound", "uterine leiomyoma", "adenomyosis"],
        "ğŸ§¬ ç²¾æº–": ["genetic test", "targeted therapy"]
    }
    
    sel_cat = st.multiselect("é¡åˆ¥", list(KEYWORDS.keys()), ["ğŸ¥š å©¦ç™Œ"])
    base_k = []
    for c in sel_cat: base_k.extend(KEYWORDS[c])
    cust_k = st.text_input("è‡ªè¨‚é—œéµå­—", help="e.g. TP53")
    if cust_k: base_k.extend([k.strip() for k in cust_k.split(",")])
    final_k = st.multiselect("é—œéµå­—", base_k, base_k)

    use_j = st.checkbox("é™å®šæœŸåˆŠ", True)
    PRESET_J = ["New England Journal of Medicine", "The Lancet Oncology", "Journal of Clinical Oncology", "Gynecologic Oncology", "Journal of Gynecologic Oncology"]
    final_j = st.multiselect("æœŸåˆŠ", PRESET_J, PRESET_J) if use_j else []

    st.divider()

    # 4. æ™‚é–“è¨­å®š (ä¿®å¾©éƒ¨åˆ†)
    st.subheader("ğŸ“… æ™‚é–“è¨­å®š")
    date_mode = st.radio("æ¨¡å¼", ["æœ€è¿‘å¹¾å¤©", "æŒ‡å®šå€é–“"], index=0)
    
    date_range_query = ""
    date_params = {} # ç”¨æ–¼å­˜æ”¾ reldate ç­‰åƒæ•¸

    if date_mode == "æœ€è¿‘å¹¾å¤©":
        days_back = st.slider("å¹¾å¤©å…§?", 1, 90, 14)
        date_params = {"reldate": days_back}
    else:
        col1, col2 = st.columns(2)
        with col1: day_start = st.number_input("å¹¾å¤©å‰é–‹å§‹?", 1, 365, 60)
        with col2: day_end = st.number_input("å¹¾å¤©å‰çµæŸ?", 0, 365, 30)
        
        # å»ºç«‹ PubMed æ—¥æœŸå€é–“èªæ³•
        today = datetime.now()
        d_min = (today - timedelta(days=day_start)).strftime("%Y/%m/%d")
        d_max = (today - timedelta(days=day_end)).strftime("%Y/%m/%d")
        # æ³¨æ„ï¼šPubMed èªæ³•éœ€è¦å‰å¾Œç©ºæ ¼
        date_range_query = f' AND ("{d_min}"[Date - Publication] : "{d_max}"[Date - Publication])'

    max_res = st.number_input("ç¯‡æ•¸ä¸Šé™", 1, 100, 20)
    
    if st.button("ğŸš€ æ¥µé€Ÿæœå°‹", type="primary"):
        if not api_key: st.error("è«‹è¼¸å…¥ API Key")
        else:
            st.session_state.articles_data = []
            st.session_state.search_trigger = True

# --- æ ¸å¿ƒå‡½æ•¸ ---

def build_query(keywords, journals, date_str_query):
    # åŸºç¤é—œéµå­—
    if not keywords: return ""
    term_q = "(" + " OR ".join([f'"{k}"[Title/Abstract]' for k in keywords]) + ")"
    
    # åŠ ä¸ŠæœŸåˆŠ
    final = term_q
    if journals:
        journal_q = "(" + " OR ".join([f'"{j}"[Journal]' for j in journals]) + ")"
        final = f"{term_q} AND {journal_q}"
    
    # åŠ ä¸Šæ—¥æœŸå€é–“èªæ³• (å¦‚æœæ˜¯æŒ‡å®šå€é–“æ¨¡å¼)
    if date_str_query:
        final += date_str_query
        
    return final

def fetch_headers(query, date_params, limit, email):
    Entrez.email = email
    try:
        search_args = {"db": "pubmed", "term": query, "retmax": limit, "sort": "date"}
        # å¦‚æœæ˜¯ã€Œæœ€è¿‘å¹¾å¤©ã€ï¼ŒåŠ å…¥ reldate åƒæ•¸
        if "reldate" in date_params: 
            search_args["reldate"] = date_params["reldate"]
        
        # ç¬¬ä¸€æ­¥ï¼šæœå°‹ ID
        h = Entrez.esearch(**search_args)
        r = Entrez.read(h)
        ids = r["IdList"]
        if not ids: return []
        
        # ç¬¬äºŒæ­¥ï¼šæŠ“å–è©³ç´°è³‡æ–™
        h = Entrez.efetch(db="pubmed", id=ids, retmode="xml")
        arts = Entrez.read(h)
        parsed = []
        for art in arts['PubmedArticle']:
            try:
                cit = art['MedlineCitation']
                ti = cit['Article']['ArticleTitle']
                jo = cit['Article']['Journal']['Title']
                ab = " ".join([str(x) for x in cit['Article']['Abstract']['AbstractText']]) if 'Abstract' in cit['Article'] else "No Abstract"
                ids = art['PubmedData']['ArticleIdList']
                doi = next((i for i in ids if i.attributes['IdType']=='doi'), None)
                link = f"[https://doi.org/](https://doi.org/){doi}" if doi else f"[https://pubmed.ncbi.nlm.nih.gov/](https://pubmed.ncbi.nlm.nih.gov/){ids[0]}/"
                parsed.append({"id": ids[0], "title":ti, "journal":jo, "abstract":ab, "link":link, "title_zh": "ç¿»è­¯ä¸­..."})
            except: continue
        return parsed
    except Exception as e:
        st.error(f"PubMed Error: {e}")
        return []

# --- å¹³è¡Œç¿»è­¯é‚è¼¯ (Multithreading) ---

def translate_chunk(chunk, key):
    if not chunk: return []
    titles = "\n".join([f"{i+1}. {art['title']}" for i, art in enumerate(chunk)])
    url = f"[https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=](https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=){key}"
    headers = {'Content-Type': 'application/json'}
    prompt = f"Translate titles to Traditional Chinese (Taiwan). One per line. No numbering.\n{titles}"
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    try:
        res = requests.post(url, headers=headers, data=json.dumps(payload))
        if res.status_code == 200:
            lines = [l.strip() for l in res.json()['candidates'][0]['content']['parts'][0]['text'].strip().split('\n') if l.strip()]
            for i, art in enumerate(chunk):
                if i < len(lines):
                    clean = lines[i].split(". ", 1)[-1] if ". " in lines[i][:4] else lines[i]
                    art['title_zh'] = clean
                else: art['title_zh'] = art['title']
    except: pass
    return chunk

def batch_translate_parallel(articles, key):
    chunk_size = 10
    chunks = [articles[i:i+chunk_size] for i in range(0, len(articles), chunk_size)]
    results = []
    # ä½¿ç”¨ 3 å€‹åŸ·è¡Œç·’ä¸¦ç™¼
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        futures = {executor.submit(translate_chunk, c, key): c for c in chunks}
        for future in concurrent.futures.as_completed(futures):
            try: results.extend(future.result())
            except: pass
    # ç°¡å–®æ’åºå›åŸæœ¬é †åº (ä¾è³´æ¨™é¡ŒåŒ¹é…)
    title_map = {r['title']: r for r in results}
    final_ordered = []
    for art in articles:
        if art['title'] in title_map: final_ordered.append(title_map[art['title']])
        else: final_ordered.append(art)
    return final_ordered

# --- æ·±åº¦åˆ†æé‚è¼¯ (JSON) ---

def run_deep_analysis_json(art, key):
    url = f"[https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=](https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=){key}"
    headers = {'Content-Type': 'application/json'}
    prompt = f"""
    Analyze abstract. Return JSON only. Keys: methods, rationale, results, implication. Values in Traditional Chinese.
    Title: {art['title']}
    Abstract: {art['abstract']}
    """
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    try:
        res = requests.post(url, headers=headers, data=json.dumps(payload))
        if res.status_code == 200:
            txt = clean_json_text(res.json()['candidates'][0]['content']['parts'][0]['text'])
            data = json.loads(txt)
            return f"""
            <div style="background:#fff; padding:15px; border-radius:8px; border:1px solid #eee;">
                <h4 style="color:#2e86c1;">1. ğŸ§ª ç ”ç©¶æ–¹æ³•</h4><div>{data.get('methods','')}</div>
                <h4 style="color:#2e86c1;">2. ğŸ’¡ ç™¼æƒ³ç·£èµ·</h4><div>{data.get('rationale','')}</div>
                <h4 style="color:#2e86c1;">3. ğŸ“Š çµæœæ•¸æ“š</h4><div>{data.get('results','')}</div>
                <h4 style="color:#d35400;">4. ğŸ¥ è‡¨åºŠé‹ç”¨</h4><div>{data.get('implication','')}</div>
            </div>
            """
    except: return "<div style='color:red'>åˆ†æå¤±æ•—</div>"
    return "<div style='color:red'>é€£ç·šå¤±æ•—</div>"

def send_mail(to, pwd, queue):
    msg = MIMEMultipart()
    msg['From'] = to
    msg['To'] = to
    msg['Subject'] = f"GynOnc Report {datetime.now().strftime('%Y-%m-%d')}"
    body = "<html><body><h2>æ–‡ç»å ±å‘Š</h2><hr>" + "".join([i['html'] + "<hr>" for i in queue]) + "</body></html>"
    msg.attach(MIMEText(body, 'html'))
    try:
        s = smtplib.SMTP('smtp.gmail.com', 587); s.starttls()
        s.login(to, pwd); s.send_message(msg); s.quit()
        return True, "OK"
    except Exception as e: return False, str(e)

# --- ä¸»æµç¨‹ ---

st.title("âš¡ GynOnc æ¥µé€Ÿæ–‡ç»ç³»çµ± v9.0")

if st.session_state.search_trigger:
    # ç¢ºä¿ email è®Šæ•¸å­˜åœ¨
    search_email = "lionsmanic@gmail.com"
    if 'EMAIL_ADDRESS' in st.secrets: search_email = st.secrets['EMAIL_ADDRESS']
    
    with st.status("ğŸš€ æœå°‹ä¸¦å¹³è¡Œç¿»è­¯ä¸­...", expanded=True) as status:
        # å»ºç«‹æŸ¥è©¢
        q = build_query(final_k, final_j, date_range_query)
        st.write(f"èªæ³•: `{q[:60]}...`")
        
        # æŠ“å–æ¨™é¡Œ
        raw = fetch_headers(q, date_params, max_res, search_email)
        
        if raw:
            st.write(f"âœ… æ‰¾åˆ° {len(raw)} ç¯‡ï¼Œå•Ÿå‹•å¤šæ ¸å¿ƒç¿»è­¯...")
            # å¹³è¡Œç¿»è­¯
            final_list = batch_translate_parallel(raw, api_key)
            st.session_state.articles_data = final_list
            status.update(label="å®Œæˆï¼", state="complete")
        else:
            status.update(label="âŒ æ‰¾ä¸åˆ°æ–‡ç«  (è«‹æª¢æŸ¥æ—¥æœŸæˆ–é—œéµå­—)", state="error")
    st.session_state.search_trigger = False

# é¡¯ç¤ºçµæœ
if st.session_state.articles_data:
    st.divider()
    for i, art in enumerate(st.session_state.articles_data):
        with st.container():
            c1, c2 = st.columns([5, 1])
            with c1:
                st.markdown(f"**{i+1}. {art['title']}**")
                # è—è‰²å¤§æ¨™é¡Œé¡¯ç¤ºä¸­æ–‡
                st.markdown(f"<h4 style='color:#1a5276; margin-top:0;'>{art.get('title_zh', '...')}</h4>", unsafe_allow_html=True)
                st.caption(f"ğŸ“– {art['journal']} | [Link]({art['link']})")
            
            with c2:
                if st.button("ğŸ” è©³ç´°åˆ†æ", key=f"btn_{i}"):
                    with st.spinner("åˆ†æä¸­..."):
                        if art['id'] not in st.session_state.analysis_cache:
                            report = run_deep_analysis_json(art, api_key)
                            st.session_state.analysis_cache[art['id']] = report
                            st.session_state.email_queue.append({
                                "title": art['title'],
                                "html": f"<h3>{art['title']}</h3><h4>{art['title_zh']}</h4>{report}"
                            })
                            st.rerun()

            if art['id'] in st.session_state.analysis_cache:
                with st.expander("ğŸ©º æ·±åº¦å ±å‘Š", expanded=True):
                    st.markdown(st.session_state.analysis_cache[art['id']], unsafe_allow_html=True)
            st.markdown("---")

if getattr(st.session_state, 'trigger_email', False):
    m_to = "lionsmanic@gmail.com"
    m_pwd = ""
    if 'EMAIL_ADDRESS' in st.secrets: m_to = st.secrets['EMAIL_ADDRESS']
    if 'EMAIL_PASSWORD' in st.secrets: m_pwd = st.secrets['EMAIL_PASSWORD']
    
    ok, msg = send_mail(m_to, m_pwd, st.session_state.email_queue)
    if ok: 
        st.sidebar.success("å·²å¯„å‡º")
        st.session_state.email_queue = []
    else: st.sidebar.error(f"å¤±æ•—: {msg}")
    st.session_state.trigger_email = False
