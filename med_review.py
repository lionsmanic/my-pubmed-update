import streamlit as st
from Bio import Entrez
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime, timedelta
import time
import requests
import json

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="GynOnc æ–‡ç»ç³»çµ± v5.0 (ç©©å®šç‰ˆ)", page_icon="ğŸ›¡ï¸", layout="wide")

# --- Session State ---
if 'articles_data' not in st.session_state: st.session_state.articles_data = []
if 'analysis_cache' not in st.session_state: st.session_state.analysis_cache = {}
if 'email_queue' not in st.session_state: st.session_state.email_queue = []
if 'search_trigger' not in st.session_state: st.session_state.search_trigger = False

# --- æ ¸å¿ƒå·¥å…·ï¼šå¸¶æœ‰è‡ªå‹•é‡è©¦åŠŸèƒ½çš„ API å‘¼å« ---
def call_gemini_api(url, payload, retries=3):
    """
    ç™¼é€ API è«‹æ±‚ï¼Œå¦‚æœé‡åˆ° 503 (Overloaded) æˆ– 429 (Rate Limit)ï¼Œ
    æœƒè‡ªå‹•ç­‰å¾…ä¸¦é‡è©¦ï¼Œæœ€å¤š retries æ¬¡ã€‚
    """
    headers = {'Content-Type': 'application/json'}
    
    for attempt in range(retries):
        try:
            response = requests.post(url, headers=headers, data=json.dumps(payload))
            
            # 200 OK
            if response.status_code == 200:
                return response.json()
            
            # 503 Service Unavailable (Overloaded) æˆ– 429 Too Many Requests
            elif response.status_code in [503, 429]:
                wait_time = (attempt + 1) * 2  # ç¬¬ä¸€æ¬¡ç­‰2ç§’, ç¬¬äºŒæ¬¡ç­‰4ç§’...
                time.sleep(wait_time)
                continue # é‡è©¦
            
            # å…¶ä»–éŒ¯èª¤ (400, 403, 404) -> ç›´æ¥å›å‚³éŒ¯èª¤ï¼Œä¸é‡è©¦
            else:
                return {"error": f"HTTP {response.status_code}: {response.text}"}
                
        except Exception as e:
            time.sleep(1)
            continue

    return {"error": "Maximum retries exceeded (ç³»çµ±å¿™ç¢Œï¼Œè«‹ç¨å¾Œå†è©¦)"}

# --- æ ¸å¿ƒå‡½æ•¸ï¼šæ¨¡å‹åµæ¸¬ ---
def get_available_models(api_key):
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
    try:
        response = requests.get(url)
        if response.status_code == 200:
            data = response.json()
            models = [m['name'].replace('models/', '') for m in data.get('models', []) 
                      if 'generateContent' in m.get('supportedGenerationMethods', [])]
            return models
        return []
    except: return []

# --- å´é‚Šæ¬„ ---
with st.sidebar:
    st.header("ğŸ›¡ï¸ è¨­å®š (ç©©å®šç‰ˆ)")
    
    # 1. API Key
    if 'GEMINI_API_KEY' in st.secrets:
        api_key = st.secrets['GEMINI_API_KEY']
        st.success("ğŸ”‘ API Key å·²è¼‰å…¥")
    else:
        api_key = st.text_input("Gemini API Key", type="password")

    selected_model_name = None
    if api_key:
        available_models = get_available_models(api_key)
        if available_models:
            default_ix = 0
            if 'gemini-1.5-flash' in available_models: default_ix = available_models.index('gemini-1.5-flash')
            elif 'gemini-pro' in available_models: default_ix = available_models.index('gemini-pro')
            selected_model_name = st.selectbox("âœ… AI æ¨¡å‹:", available_models, index=default_ix)

    # 2. Email
    if 'EMAIL_ADDRESS' in st.secrets: user_email = st.secrets['EMAIL_ADDRESS']
    else: user_email = st.text_input("Email", "lionsmanic@gmail.com")
    
    if 'EMAIL_PASSWORD' in st.secrets: email_password = st.secrets['EMAIL_PASSWORD']
    else: email_password = st.text_input("Gmail App Password", type="password")

    st.divider()
    
    # 3. æœå°‹æ¢ä»¶
    st.subheader("ğŸ” æœå°‹æ¢ä»¶")
    KEYWORDS = {
        "ğŸ¥š å©¦ç™Œ (Gyn Onc)": ["cervical cancer", "ovarian cancer", "endometrial cancer", "immunotherapy", "robotic surgery"],
        "ğŸŒŠ æµ·æ‰¶åˆ€ (HIFU)": ["HIFU", "high intensity focused ultrasound", "uterine leiomyoma", "adenomyosis"],
        "ğŸ§¬ ç²¾æº–/å…¶ä»–": ["genetic test", "targeted therapy"]
    }
    
    selected_cats = st.multiselect("ğŸ“š ä¸»é¡Œ", list(KEYWORDS.keys()), default=["ğŸ¥š å©¦ç™Œ (Gyn Onc)"])
    base_keywords = []
    for cat in selected_cats: base_keywords.extend(KEYWORDS[cat])
    
    custom_keywords_str = st.text_input("â• è‡ªè¨‚é—œéµå­—", help="ä¾‹å¦‚: TP53")
    if custom_keywords_str: base_keywords.extend([k.strip() for k in custom_keywords_str.split(",")])
    
    final_keywords = st.multiselect("é—œéµå­—", base_keywords, default=base_keywords)

    use_journals = st.checkbox("é™å®šæœŸåˆŠ?", value=True)
    PRESET_JOURNALS = ["New England Journal of Medicine", "The Lancet Oncology", "Journal of Clinical Oncology", "Gynecologic Oncology", "Journal of Gynecologic Oncology"]
    final_journals = st.multiselect("æœŸåˆŠåˆ—è¡¨", PRESET_JOURNALS, default=PRESET_JOURNALS) if use_journals else []

    st.divider()

    # 4. æ™‚é–“èˆ‡æ•¸é‡
    date_mode = st.radio("ğŸ“… æ™‚é–“", ["æœ€è¿‘å¹¾å¤©", "æŒ‡å®šå€é–“"], index=0)
    date_range_query = ""
    date_params = {}
    
    if date_mode == "æœ€è¿‘å¹¾å¤©":
        days_back = st.slider("éå»å¹¾å¤©?", 1, 90, 14)
        date_params = {"reldate": days_back}
    else:
        col1, col2 = st.columns(2)
        with col1: day_start = st.number_input("å¹¾å¤©å‰é–‹å§‹?", 1, 365, 60)
        with col2: day_end = st.number_input("å¹¾å¤©å‰çµæŸ?", 0, 365, 30)
        today = datetime.now()
        d_min = (today - timedelta(days=day_start)).strftime("%Y/%m/%d")
        d_max = (today - timedelta(days=day_end)).strftime("%Y/%m/%d")
        date_range_query = f' AND ("{d_min}"[Date - Publication] : "{d_max}"[Date - Publication])'

    max_results = st.number_input("ç¯‡æ•¸ä¸Šé™", 1, 100, 20)
    
    if st.button("ğŸš€ æ¥µé€Ÿæœå°‹", type="primary", disabled=(not selected_model_name)):
        st.session_state.articles_data = []
        st.session_state.analysis_cache = {}
        st.session_state.email_queue = []
        st.session_state.search_trigger = True

# --- æ ¸å¿ƒå‡½æ•¸ ---

def build_query(keywords, journals, date_str_query):
    if not keywords: return ""
    term_q = "(" + " OR ".join([f'"{k}"[Title/Abstract]' for k in keywords]) + ")"
    final = term_q
    if journals:
        journal_q = "(" + " OR ".join([f'"{j}"[Journal]' for j in journals]) + ")"
        final = f"{term_q} AND {journal_q}"
    if date_str_query: final += date_str_query
    return final

def fetch_headers(query, date_params, limit, email):
    Entrez.email = email
    try:
        search_args = {"db": "pubmed", "term": query, "retmax": limit, "sort": "date"}
        if "reldate" in date_params: search_args["reldate"] = date_params["reldate"]
        
        h = Entrez.esearch(**search_args)
        r = Entrez.read(h)
        ids = r["IdList"]
        if not ids: return []
        
        h = Entrez.efetch(db="pubmed", id=ids, retmode="xml")
        arts = Entrez.read(h)
        parsed = []
        for art in arts['PubmedArticle']:
            try:
                cit = art['MedlineCitation']
                ti = cit['Article']['ArticleTitle']
                jo = cit['Article']['Journal']['Title']
                ab = " ".join([str(x) for x in cit['Article']['Abstract']['AbstractText']]) if 'Abstract' in cit['Article'] else "No Abstract"
                ids = art['PubmedData']['ArticleIdList']
                doi = next((i for i in ids if i.attributes['IdType']=='doi'), None)
                link = f"https://doi.org/{doi}" if doi else f"https://pubmed.ncbi.nlm.nih.gov/{ids[0]}/"
                parsed.append({"id": ids[0], "title":ti, "journal":jo, "abstract":ab, "link":link, "title_zh": "ç¿»è­¯ä¸­..."})
            except: continue
        return parsed
    except Exception as e:
        st.error(f"PubMed Error: {e}"); return []

def chunk_list(lst, n):
    """å°‡åˆ—è¡¨åˆ‡åˆ†æˆå°å¡Šï¼Œé¿å…ä¸€æ¬¡é€å¤ªå¤š"""
    for i in range(0, len(lst), n):
        yield lst[i:i + n]

def batch_translate_titles_robust(articles, key, model_name):
    """
    åˆ†æ‰¹ç¿»è­¯æ¨™é¡Œï¼Œæ¯æ¬¡åªç¿»è­¯ 5 ç¯‡ï¼Œé™ä½ 503 éŒ¯èª¤æ©Ÿç‡
    """
    if not articles: return []
    
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={key}"
    
    # å°‡æ–‡ç« åˆ†æˆæ¯ 5 ç¯‡ä¸€çµ„
    chunk_size = 5
    article_chunks = list(chunk_list(articles, chunk_size))
    
    progress_bar = st.progress(0)
    
    for idx, chunk in enumerate(article_chunks):
        titles_text = "\n".join([f"{i+1}. {art['title']}" for i, art in enumerate(chunk)])
        
        prompt = f"""
        ä»»å‹™ï¼šç¿»è­¯ä»¥ä¸‹ {len(chunk)} å€‹é†«å­¸æ¨™é¡Œç‚ºç¹é«”ä¸­æ–‡ã€‚
        æ ¼å¼ï¼šä¸€è¡Œä¸€å€‹çµæœï¼Œåš´ç¦ç·¨è™Ÿï¼Œåš´ç¦å¤šé¤˜æ–‡å­—ã€‚
        åŸæ–‡ï¼š
        {titles_text}
        """
        payload = {"contents": [{"parts": [{"text": prompt}]}]}
        
        # ä½¿ç”¨å¸¶æœ‰é‡è©¦æ©Ÿåˆ¶çš„å‘¼å«
        result = call_gemini_api(url, payload)
        
        if "error" not in result:
            try:
                res_text = result['candidates'][0]['content']['parts'][0]['text']
                zh_titles = [line.strip() for line in res_text.strip().split('\n') if line.strip()]
                
                for i, art in enumerate(chunk):
                    if i < len(zh_titles):
                        clean = zh_titles[i].split(". ", 1)[-1] if ". " in zh_titles[i][:4] else zh_titles[i]
                        art['title_zh'] = clean
                    else:
                        art['title_zh'] = "(ç¿»è­¯æ ¼å¼éŒ¯èª¤)"
            except:
                for art in chunk: art['title_zh'] = "(è§£æå¤±æ•—)"
        else:
            for art in chunk: art['title_zh'] = "(ç¿»è­¯é€£ç·šé€¾æ™‚)"
            
        # æ›´æ–°é€²åº¦æ¢
        progress_bar.progress((idx + 1) / len(article_chunks))
        time.sleep(0.5) # ç¨å¾®ä¼‘æ¯ä¸€ä¸‹ï¼Œå° API æº«æŸ”ä¸€é»
        
    return articles

def run_deep_analysis_robust(art, key, model_name):
    """
    æ·±åº¦åˆ†æ (å«é‡è©¦æ©Ÿåˆ¶ + HTML å¼·åˆ¶æ ¼å¼)
    """
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={key}"
    
    prompt_text = f"""
    è§’è‰²ï¼šè³‡æ·±å©¦ç™Œæ¬Šå¨é†«å¸«ã€‚
    æ¨™é¡Œï¼š{art['title']}
    æ‘˜è¦ï¼š{art['abstract']}
    
    ã€è¼¸å‡ºæ ¼å¼è¦æ±‚ã€‘ï¼š
    1. è¼¸å‡º **ç´” HTML**ã€‚
    2. **åš´ç¦** Markdownã€‚
    3. æ‰€æœ‰æ¨™é¡Œç”¨ <h4 style="color:#2e86c1;">ã€‚
    4. å…¨éƒ¨åŒ…åœ¨ <div> å…§ã€‚
    
    æ¨¡æ¿ï¼š
    <div style="font-family: sans-serif; line-height: 1.6;">
        <h4 style="color:#2e86c1; margin-top:0; border-bottom: 2px solid #eee;">1. ğŸ§ª ç ”ç©¶æ–¹æ³• (Methods)</h4>
        <p>ç°¡è¿° Study Design, Patient Populationã€‚</p>
        
        <h4 style="color:#2e86c1; border-bottom: 2px solid #eee;">2. ğŸ’¡ ç™¼æƒ³ç·£èµ· (Rationale)</h4>
        <p>ç‚ºä½•åšæ­¤ç ”ç©¶ï¼Ÿè§£æ±ºä»€éº¼ç—›é»ï¼Ÿ</p>
        
        <h4 style="color:#2e86c1; border-bottom: 2px solid #eee;">3. ğŸ“Š çµæœæ•¸æ“š (Results)</h4>
        <ul><li>é—œéµæ•¸æ“š (P-value, HR)...</li></ul>
        
        <h4 style="color:#d35400; border-bottom: 2px solid #eee;">4. ğŸ¥ è‡¨åºŠé‹ç”¨ (Implication)</h4>
        <p>è‡¨åºŠå»ºè­°ã€‚</p>
    </div>
    """
    
    payload = {"contents": [{"parts": [{"text": prompt_text}]}]}
    
    # å‘¼å« API (å¸¶é‡è©¦)
    result = call_gemini_api(url, payload)
    
    if "error" in result:
        # å¦‚æœé‡è©¦å¤šæ¬¡é‚„æ˜¯å¤±æ•—ï¼Œå›å‚³ç´…å­—éŒ¯èª¤
        return f"<div style='color:red; border:1px solid red; padding:10px;'>âŒ åˆ†æå¤±æ•— (ç³»çµ±å¿™ç¢Œ): {result['error']}</div>"
    
    try:
        txt = result['candidates'][0]['content']['parts'][0]['text']
        return txt.replace("```html", "").replace("```", "").strip()
    except Exception as e:
        return f"<div style='color:red'>è§£æéŒ¯èª¤: {str(e)}</div>"

def send_bulk_email(to, pwd, queue):
    if not queue: return False, "æ¸…å–®ç‚ºç©º"
    msg = MIMEMultipart()
    msg['From'] = to
    msg['To'] = to
    msg['Subject'] = f"GynOnc æ–‡ç»å½™å ± ({len(queue)}ç¯‡) - {datetime.now().strftime('%Y-%m-%d')}"
    
    body = """
    <html><body style="font-family: Arial, sans-serif; color: #333;">
    <h2 style="color: #2c3e50;">ğŸ§¬ æ–‡ç»åˆ†æå ±å‘Š</h2>
    <hr>
    """
    for item in queue:
        body += item['html']
        body += "<hr style='margin: 30px 0; border: 0; border-top: 1px solid #eee;'>"
    body += "</body></html>"
    
    msg.attach(MIMEText(body, 'html'))
    try:
        s = smtplib.SMTP('smtp.gmail.com', 587)
        s.starttls()
        s.login(to, pwd)
        s.send_message(msg); s.quit()
        return True, "å·²å¯„å‡º"
    except Exception as e: return False, str(e)

# --- ä¸»ç¨‹å¼ ---

st.title("ğŸ›¡ï¸ GynOnc æ–‡ç»ç³»çµ± v5.0")
st.caption("ç©©å®šç‰ˆï¼šå…§å»º 503 è‡ªå‹•é‡è©¦èˆ‡åˆ†æ‰¹è™•ç†æ©Ÿåˆ¶")

# 1. æœå°‹
if st.session_state.search_trigger:
    with st.status("ğŸ” æ­£åœ¨åŸ·è¡Œç©©å®šæœå°‹...", expanded=True) as status:
        q = build_query(final_keywords, final_journals, date_range_query)
        st.write(f"æœå°‹èªæ³•: `{q[:50]}...`")
        
        raw_articles = fetch_headers(q, date_params, max_results, user_email)
        
        if raw_articles:
            st.write(f"âœ… æ‰¾åˆ° {len(raw_articles)} ç¯‡")
            st.write("ğŸ”„ æ­£åœ¨åˆ†æ‰¹ç¿»è­¯æ¨™é¡Œ (æ¯5ç¯‡ä¸€çµ„ï¼Œé¿å…ç•¶æ©Ÿ)...")
            
            # ä½¿ç”¨åˆ†æ‰¹ç¿»è­¯å‡½æ•¸
            translated_articles = batch_translate_titles_robust(raw_articles, api_key, selected_model_name)
            
            st.session_state.articles_data = translated_articles
            status.update(label="æœå°‹å®Œæˆï¼", state="complete")
        else:
            status.update(label="âŒ æ‰¾ä¸åˆ°æ–‡ç« ", state="error")
    
    st.session_state.search_trigger = False

# 2. åˆ—è¡¨
if st.session_state.articles_data:
    st.divider()
    st.markdown(f"### ğŸ“š çµæœåˆ—è¡¨ ({len(st.session_state.articles_data)} ç¯‡)")
    
    for i, art in enumerate(st.session_state.articles_data):
        with st.container():
            col1, col2 = st.columns([5, 1])
            with col1:
                st.markdown(f"**{i+1}. {art['title']}**")
                # é¡¯ç¤ºä¸­æ–‡æ¨™é¡Œï¼Œè‹¥å¤±æ•—æœƒé¡¯ç¤ºåŸå› 
                st.markdown(f"<span style='color:#2e86c1; font-size:1.1em;'>{art.get('title_zh', 'ç¿»è­¯ä¸­...')}</span>", unsafe_allow_html=True)
                st.caption(f"ğŸ“– {art['journal']} | [é€£çµ]({art['link']})")
            
            with col2:
                btn_key = f"analyze_{art['id']}_{i}"
                if st.button("ğŸ” è©³ç´°åˆ†æ", key=btn_key):
                    # åŸ·è¡Œåˆ†æ (å¸¶æœ‰é‡è©¦æ©Ÿåˆ¶)
                    with st.spinner("AI æ­£åœ¨æ·±åº¦é–±è®€ (è‹¥å¿™ç¢Œå°‡è‡ªå‹•é‡è©¦)..."):
                        if art['id'] not in st.session_state.analysis_cache:
                            report = run_deep_analysis_robust(art, api_key, selected_model_name)
                            st.session_state.analysis_cache[art['id']] = report
                            
                            email_item = {
                                "title": art['title'],
                                "html": f"""
                                <div style="background-color: #f9f9f9; padding: 20px; border-radius: 5px; margin-bottom: 20px;">
                                    <h3 style="margin-top: 0; color: #1a5276;"><a href='{art['link']}' style="text-decoration: none; color: #1a5276;">{art['title']}</a></h3>
                                    <h4 style="margin-top: 5px; color: #2e86c1;">{art.get('title_zh', '')}</h4>
                                    <p style="color: #666; font-size: 0.9em;">ğŸ“– {art['journal']}</p>
                                    {report}
                                </div>
                                """
                            }
                            if not any(d['title'] == art['title'] for d in st.session_state.email_queue):
                                st.session_state.email_queue.append(email_item)

            if art['id'] in st.session_state.analysis_cache:
                with st.expander("ğŸ©º åˆ†æå ±å‘Š", expanded=True):
                    st.markdown(st.session_state.analysis_cache[art['id']], unsafe_allow_html=True)
            st.markdown("---")

# 3. å¯„ä¿¡
if st.session_state.email_queue:
    st.sidebar.divider()
    st.sidebar.header(f"ğŸ›’ è³¼ç‰©è»Š ({len(st.session_state.email_queue)})")
    if st.sidebar.button("ğŸ“© æ‰“åŒ…å¯„å‡º"):
        if not email_password: st.sidebar.error("ç¼ºå¯†ç¢¼")
        else:
            ok, msg = send_bulk_email(user_email, email_password, st.session_state.email_queue)
            if ok: 
                st.sidebar.success("å·²å¯„å‡ºï¼")
                st.session_state.email_queue = []
            else: st.sidebar.error(msg)
